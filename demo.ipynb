{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## 基于yolov5的数独检测\n",
        "### 0.环境安装"
      ],
      "metadata": {
        "collapsed": false,
        "id": "rSiWMcPFMopn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'sudoku'...\n",
            "remote: Enumerating objects: 28, done.\u001b[K\n",
            "remote: Counting objects: 100% (28/28), done.\u001b[K\n",
            "remote: Compressing objects: 100% (22/22), done.\u001b[K\n",
            "remote: Total 28 (delta 7), reused 21 (delta 4), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (28/28), 25.15 MiB | 11.69 MiB/s, done.\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCloning into 'yolov5'...\n",
            "remote: Enumerating objects: 15598, done.\u001b[K\n",
            "remote: Counting objects: 100% (205/205), done.\u001b[K\n",
            "remote: Compressing objects: 100% (151/151), done.\u001b[K\n",
            "remote: Total 15598 (delta 98), reused 115 (delta 54), pack-reused 15393\u001b[K\n",
            "Receiving objects: 100% (15598/15598), 14.64 MiB | 28.55 MiB/s, done.\n",
            "Resolving deltas: 100% (10626/10626), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/pk5ls20/sudoku.git\n",
        "!mv sudoku/* .\n",
        "%pip install -qr requirements.txt\n",
        "!git clone https://github.com/ultralytics/yolov5.git"
      ],
      "metadata": {
        "id": "YVSI364EMopp",
        "outputId": "e3e184b4-229d-403c-83b1-f161d1a5d0a5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.提取数独"
      ],
      "metadata": {
        "collapsed": false,
        "id": "6hb90fvEMopq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torch/hub.py:286: UserWarning: You are about to download and run code from an untrusted repository. In a future release, this won't be allowed. To add the repository to your trusted list, change the command to {calling_fn}(..., trust_repo=False) and a command prompt will appear asking for an explicit confirmation of trust, or load(..., trust_repo=True), which will assume that the prompt is to be answered with 'yes'. You can also use load(..., trust_repo='check') which will only prompt for confirmation if the repo is not already trusted. This will eventually be the default behaviour\n",
            "  warnings.warn(\n",
            "Downloading: \"https://github.com/ultralytics/yolov5/zipball/master\" to /root/.cache/torch/hub/master.zip\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31m\u001b[1mrequirements:\u001b[0m /root/.cache/torch/hub/requirements.txt not found, check failed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fusing layers... \n",
            "Model summary: 157 layers, 7012822 parameters, 0 gradients, 15.8 GFLOPs\n",
            "Adding AutoShape... \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "正在处理1.png...提取成功！\n",
            "Done on 2023-04-27 03:02:14.253200\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import datetime\n",
        "import cv2\n",
        "model = torch.hub.load('ultralytics/yolov5', 'custom', path='detect_sudoku.pt')\n",
        "input_path = 'sudoku_pic'\n",
        "output_path = 'sudoku_pic/extract'\n",
        "timex = lambda :datetime.datetime.now()\n",
        "for file_name in os.listdir(input_path):\n",
        "    if file_name.endswith('.jpg') or file_name.endswith('.png'):\n",
        "        print(f\"正在处理{file_name}\", end='')\n",
        "        img = cv2.imread(os.path.join(input_path, file_name))\n",
        "        # 使用YOLOv5检测\n",
        "        results = model(img)\n",
        "        # 得到置信度最高的数独检测结果\n",
        "        sudoku_detection = None\n",
        "        for result in results.pred[0]:\n",
        "            if result[-1] == 0 and result[-2] > 0.8:\n",
        "                sudoku_detection = result\n",
        "                break\n",
        "        # 提取数独\n",
        "        if sudoku_detection is not None:\n",
        "            xmin, ymin, xmax, ymax, confidence = sudoku_detection[:5]\n",
        "            sudoku = img[int(ymin):int(ymax), int(xmin):int(xmax)]\n",
        "            cv2.imwrite(os.path.join(output_path, f\"extract_{file_name}\"), sudoku)\n",
        "            print(f\"...提取成功！\")\n",
        "        else:\n",
        "            print(f\"...{file_name}未检测到数独！\")\n",
        "print(f\"Done on {timex()}\")"
      ],
      "metadata": {
        "id": "LKDd4Zs0Mopq",
        "outputId": "450aa470-f2de-4d47-ecb0-af7ea6cd7872",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.提取数独中的数字"
      ],
      "metadata": {
        "collapsed": false,
        "id": "FYMmP4XDMopq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done on 2023-04-27 03:02:17.283583\n"
          ]
        }
      ],
      "source": [
        "# Iterate over images in input folder\n",
        "fp = list(os.listdir(output_path))\n",
        "for file_name in fp:\n",
        "    if file_name.split('_')[0] != 'extract':\n",
        "        continue\n",
        "    # Load image\n",
        "    img = cv2.imread(os.path.join(output_path, file_name))\n",
        "    # Get dimensions of image\n",
        "    height, width, _ = img.shape\n",
        "    # Calculate size of each small image\n",
        "    size = int(height / 9)\n",
        "    # Iterate over rows and columns of small images\n",
        "    for row in range(9):\n",
        "        for col in range(9):\n",
        "            # Calculate coordinates of small image\n",
        "            x1 = col * size\n",
        "            y1 = row * size\n",
        "            x2 = x1 + size\n",
        "            y2 = y1 + size\n",
        "            # Crop small image from main image\n",
        "            small_img = img[y1:y2, x1:x2]\n",
        "            # Save small image to output folder\n",
        "            small_img_file_name = '{}_{}.png'.format(os.path.splitext(file_name)[0], row * 9 + col)\n",
        "            cv2.imwrite(os.path.join(output_path, small_img_file_name), small_img)\n",
        "print(f\"Done on {timex()}\")"
      ],
      "metadata": {
        "id": "lcwxRyO3Mopr",
        "outputId": "ba8f1944-8902-4749-bfd0-f9599f2c02b9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.单个数字图片预处理\n",
        "在识别单个数字之前，需要对图片进行预处理。\n",
        "受限于训练模型，进行二值化+去黑线的预处理可以大幅度提高识别准确率"
      ],
      "metadata": {
        "collapsed": false,
        "id": "FWCQKS4iMopr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done on 2023-04-27 03:02:22.273410\n"
          ]
        }
      ],
      "source": [
        "from PIL import Image, ImageOps\n",
        "import os\n",
        "\n",
        "# 读取图片并转换为黑白图\n",
        "folder_path = 'sudoku_pic/extract'\n",
        "for filename in os.listdir(folder_path):\n",
        "    if len(filename.split('_')) != 3:\n",
        "        continue\n",
        "    img = Image.open(f\"{folder_path}/{filename}\").convert('L')\n",
        "    # 获取图片的宽度和高度\n",
        "    width, height = img.size\n",
        "    cl = []\n",
        "    # 遍历每一行，如果整行像素点>=80%部分不是白色，则将该行像素点全部转换为白色\n",
        "    for y in range(height):\n",
        "        pixels = [img.getpixel((x, y)) for x in range(width)]\n",
        "        white_pixels = sum(1 for pixel in pixels if pixel == 255)\n",
        "        if white_pixels < width*0.2:\n",
        "            for x in range(width):\n",
        "                cl.append((x, y))\n",
        "    # 遍历每一列，如果整列像素点>=80%部分不是白色，则将该列像素点全部转换为白色\n",
        "    for x in range(width):\n",
        "        pixels = [img.getpixel((x, y)) for y in range(height)]\n",
        "        white_pixels = sum(1 for pixel in pixels if pixel == 255)\n",
        "        if white_pixels < height*0.2:\n",
        "            for y in range(height):\n",
        "                cl.append((x, y))\n",
        "    # 将所有的白色像素点转换为黑色\n",
        "    for x, y in cl:\n",
        "        img.putpixel((x, y), 255)\n",
        "    # 反转图片颜色\n",
        "    img = ImageOps.invert(img)\n",
        "    img.save(f\"{folder_path}/ok/ok_{filename}\")\n",
        "print(f\"Done on {timex()}\")"
      ],
      "metadata": {
        "id": "RdixvuIPMopr",
        "outputId": "095f60ed-37a9-4e98-880f-6e1ded37ac46",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.识别数字并转化为数独\n"
      ],
      "metadata": {
        "collapsed": false,
        "id": "oqzkxEAiMopr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "Model summary: 157 layers, 7037095 parameters, 0 gradients\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0 4 1 0 0 0 3 8 0]\n",
            " [5 0 0 0 4 0 0 0 7]\n",
            " [8 0 0 7 0 3 0 0 4]\n",
            " [0 0 7 0 2 0 8 0 0]\n",
            " [0 6 0 3 0 8 0 9 0]\n",
            " [0 0 3 0 9 0 6 0 0]\n",
            " [3 0 0 2 0 1 0 0 6]\n",
            " [6 0 0 0 3 0 0 0 8]\n",
            " [0 7 4 0 0 0 2 3 0]]\n",
            "Done on 2023-04-27 03:03:13.775680\n"
          ]
        }
      ],
      "source": [
        "from torchvision.transforms import ToTensor, Resize\n",
        "from pathlib import Path\n",
        "import sys\n",
        "from models.experimental import attempt_load\n",
        "from utils.general import non_max_suppression\n",
        "from utils.torch_utils import select_device\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "global sudoku_\n",
        "\n",
        "sys.path.insert(0, str(Path('yolov5')))\n",
        "\n",
        "def load_model(model_path):\n",
        "    device = select_device()\n",
        "    model = attempt_load(model_path, device)\n",
        "    model.eval()\n",
        "    return model\n",
        "\n",
        "def predict(model, image_path):\n",
        "    device = select_device()\n",
        "    img = Image.open(image_path).convert(\"RGB\")\n",
        "    img = Resize((128, 128))(img)\n",
        "    img_tensor = ToTensor()(img).unsqueeze(0).to(device)\n",
        "    pred = model(img_tensor)[0]\n",
        "    # Apply non-max suppression\n",
        "    results = non_max_suppression(pred, conf_thres=0.25, iou_thres=0.45, classes=None, agnostic=False)\n",
        "    return results, img.size\n",
        "\n",
        "def process_images(model_path, image_folder):\n",
        "    global sudoku_\n",
        "    model = load_model(model_path)\n",
        "    sudoku = np.zeros((9, 9), dtype=np.int32)\n",
        "    for img_name in sorted(os.listdir(image_folder)):\n",
        "        if img_name.startswith(\"ok_extract_\"):\n",
        "            row = int(img_name.split(\"_\")[3].split('.')[0]) // 9\n",
        "            col = int(img_name.split(\"_\")[3].split('.')[0]) % 9\n",
        "            img_path = os.path.join(image_folder, img_name)\n",
        "            results, img_size = predict(model, img_path)\n",
        "            if len(results) > 0 and len(results[0]) > 0:\n",
        "                most_likely_class = int(results[0][0][5].item())\n",
        "                sudoku[row, col] = most_likely_class\n",
        "        else:\n",
        "            continue\n",
        "    sudoku_=sudoku\n",
        "process_images(\"detect_number.pt\", \"sudoku_pic/extract/ok\")\n",
        "print(sudoku_)\n",
        "print(f\"Done on {timex()}\")"
      ],
      "metadata": {
        "id": "YdfpptdjMopr",
        "outputId": "fc9b5c1e-8241-44fc-ea30-dfc98d677ee4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.求解数独\n"
      ],
      "metadata": {
        "id": "pZ_JEi2-q78q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def solve_sudoku_from_np_array(input_array):\n",
        "    def dfs(x, y):\n",
        "        if x == 9:\n",
        "            return True\n",
        "        if y == 9:\n",
        "            return dfs(x + 1, 0)\n",
        "        if input_array[x][y]:\n",
        "            return dfs(x, y + 1)\n",
        "        \n",
        "        id = xy_id[x][y]\n",
        "        for k in range(1, 10):\n",
        "            if hang[x][k] or lie[y][k] or kuai[id][k]:\n",
        "                continue\n",
        "            input_array[x][y] = k\n",
        "            hang[x][k] = 1\n",
        "            lie[y][k] = 1\n",
        "            kuai[id][k] = 1\n",
        "            \n",
        "            if dfs(x, y + 1):\n",
        "                return True\n",
        "            \n",
        "            input_array[x][y] = 0\n",
        "            hang[x][k] = 0\n",
        "            lie[y][k] = 0\n",
        "            kuai[id][k] = 0\n",
        "        \n",
        "        return False\n",
        "\n",
        "    hang = np.zeros((9, 10), dtype=int)\n",
        "    lie = np.zeros((9, 10), dtype=int)\n",
        "    kuai = np.zeros((9, 10), dtype=int)\n",
        "\n",
        "    xy_id = np.array([\n",
        "        [0, 0, 0, 1, 1, 1, 2, 2, 2],\n",
        "        [0, 0, 0, 1, 1, 1, 2, 2, 2],\n",
        "        [0, 0, 0, 1, 1, 1, 2, 2, 2],\n",
        "        [3, 3, 3, 4, 4, 4, 5, 5, 5],\n",
        "        [3, 3, 3, 4, 4, 4, 5, 5, 5],\n",
        "        [3, 3, 3, 4, 4, 4, 5, 5, 5],\n",
        "        [6, 6, 6, 7, 7, 7, 8, 8, 8],\n",
        "        [6, 6, 6, 7, 7, 7, 8, 8, 8],\n",
        "        [6, 6, 6, 7, 7, 7, 8, 8, 8]\n",
        "    ])\n",
        "\n",
        "    for i in range(9):\n",
        "        for j in range(9):\n",
        "            if input_array[i][j] != 0:\n",
        "                num = input_array[i][j]\n",
        "                hang[i][num] = 1\n",
        "                lie[j][num] = 1\n",
        "                id = xy_id[i][j]\n",
        "                kuai[id][num] = 1\n",
        "\n",
        "    dfs(0, 0)\n",
        "\n",
        "    return input_array\n",
        "\n",
        "solve_sudoku_from_np_array(sudoku_)\n"
      ],
      "metadata": {
        "id": "jM07K3oJq-I8",
        "outputId": "aeb2b90f-8b99-458d-a910-4dc090f4f692",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[7, 4, 1, 5, 6, 2, 3, 8, 9],\n",
              "       [5, 3, 6, 8, 4, 9, 1, 2, 7],\n",
              "       [8, 2, 9, 7, 1, 3, 5, 6, 4],\n",
              "       [9, 1, 7, 6, 2, 4, 8, 5, 3],\n",
              "       [2, 6, 5, 3, 7, 8, 4, 9, 1],\n",
              "       [4, 8, 3, 1, 9, 5, 6, 7, 2],\n",
              "       [3, 9, 8, 2, 5, 1, 7, 4, 6],\n",
              "       [6, 5, 2, 4, 3, 7, 9, 1, 8],\n",
              "       [1, 7, 4, 9, 8, 6, 2, 3, 5]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ioeCFbMdrzfY"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}