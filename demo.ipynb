{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## 基于yolov5的数独检测\n",
        "### 0.环境安装"
      ],
      "metadata": {
        "collapsed": false,
        "id": "rSiWMcPFMopn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'sudoku'...\n",
            "remote: Enumerating objects: 28, done.\u001b[K\n",
            "remote: Counting objects: 100% (28/28), done.\u001b[K\n",
            "remote: Compressing objects: 100% (22/22), done.\u001b[K\n",
            "remote: Total 28 (delta 7), reused 21 (delta 4), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (28/28), 25.15 MiB | 11.69 MiB/s, done.\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCloning into 'yolov5'...\n",
            "remote: Enumerating objects: 15598, done.\u001b[K\n",
            "remote: Counting objects: 100% (205/205), done.\u001b[K\n",
            "remote: Compressing objects: 100% (151/151), done.\u001b[K\n",
            "remote: Total 15598 (delta 98), reused 115 (delta 54), pack-reused 15393\u001b[K\n",
            "Receiving objects: 100% (15598/15598), 14.64 MiB | 28.55 MiB/s, done.\n",
            "Resolving deltas: 100% (10626/10626), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/pk5ls20/sudoku.git\n",
        "!mv sudoku/* .\n",
        "%pip install -qr requirements.txt\n",
        "!git clone https://github.com/ultralytics/yolov5.git"
      ],
      "metadata": {
        "id": "YVSI364EMopp",
        "outputId": "e3e184b4-229d-403c-83b1-f161d1a5d0a5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.提取数独"
      ],
      "metadata": {
        "collapsed": false,
        "id": "6hb90fvEMopq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "Model summary: 157 layers, 7012822 parameters, 0 gradients, 15.8 GFLOPs\n",
            "Adding AutoShape... \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31m\u001b[1mrequirements:\u001b[0m /root/.cache/torch/hub/requirements.txt not found, check failed.\n",
            "正在处理1.png...提取成功！\n",
            "Done on 2023-04-27 03:29:15.493029\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import datetime\n",
        "import cv2\n",
        "model = torch.hub.load('ultralytics/yolov5', 'custom', path='detect_sudoku.pt')\n",
        "input_path = 'sudoku_pic'\n",
        "output_path = 'sudoku_pic/extract'\n",
        "timex = lambda :datetime.datetime.now()\n",
        "for file_name in os.listdir(input_path):\n",
        "    if file_name.endswith('.jpg') or file_name.endswith('.png'):\n",
        "        print(f\"正在处理{file_name}\", end='')\n",
        "        img = cv2.imread(os.path.join(input_path, file_name))\n",
        "        # 使用YOLOv5检测\n",
        "        results = model(img)\n",
        "        # 得到置信度最高的数独检测结果\n",
        "        sudoku_detection = None\n",
        "        for result in results.pred[0]:\n",
        "            if result[-1] == 0 and result[-2] > 0.8:\n",
        "                sudoku_detection = result\n",
        "                break\n",
        "        # 提取数独\n",
        "        if sudoku_detection is not None:\n",
        "            xmin, ymin, xmax, ymax, confidence = sudoku_detection[:5]\n",
        "            sudoku = img[int(ymin):int(ymax), int(xmin):int(xmax)]\n",
        "            cv2.imwrite(os.path.join(output_path, f\"extract_{file_name}\"), sudoku)\n",
        "            print(f\"...提取成功！\")\n",
        "        else:\n",
        "            print(f\"...{file_name}未检测到数独！\")\n",
        "print(f\"Done on {timex()}\")"
      ],
      "metadata": {
        "id": "LKDd4Zs0Mopq",
        "outputId": "47efa7ff-e74d-4189-8d3f-827d071673ee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.提取数独中的数字"
      ],
      "metadata": {
        "collapsed": false,
        "id": "FYMmP4XDMopq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done on 2023-04-27 03:29:24.696708\n"
          ]
        }
      ],
      "source": [
        "# Iterate over images in input folder\n",
        "fp = list(os.listdir(output_path))\n",
        "for file_name in fp:\n",
        "    if file_name.split('_')[0] != 'extract':\n",
        "        continue\n",
        "    # Load image\n",
        "    img = cv2.imread(os.path.join(output_path, file_name))\n",
        "    # Get dimensions of image\n",
        "    height, width, _ = img.shape\n",
        "    # Calculate size of each small image\n",
        "    size = int(height / 9)\n",
        "    # Iterate over rows and columns of small images\n",
        "    for row in range(9):\n",
        "        for col in range(9):\n",
        "            # Calculate coordinates of small image\n",
        "            x1 = col * size\n",
        "            y1 = row * size\n",
        "            x2 = x1 + size\n",
        "            y2 = y1 + size\n",
        "            # Crop small image from main image\n",
        "            small_img = img[y1:y2, x1:x2]\n",
        "            # Save small image to output folder\n",
        "            small_img_file_name = '{}_{}.png'.format(os.path.splitext(file_name)[0], row * 9 + col)\n",
        "            cv2.imwrite(os.path.join(output_path, small_img_file_name), small_img)\n",
        "print(f\"Done on {timex()}\")"
      ],
      "metadata": {
        "id": "lcwxRyO3Mopr",
        "outputId": "e05dc1c8-278e-42cb-b6d3-729c87d39643",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.单个数字图片预处理\n",
        "在识别单个数字之前，需要对图片进行预处理。\n",
        "受限于训练模型，进行二值化+去黑线的预处理可以大幅度提高识别准确率"
      ],
      "metadata": {
        "collapsed": false,
        "id": "FWCQKS4iMopr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done on 2023-04-27 03:29:28.393855\n"
          ]
        }
      ],
      "source": [
        "from PIL import Image, ImageOps\n",
        "import os\n",
        "\n",
        "# 读取图片并转换为黑白图\n",
        "folder_path = 'sudoku_pic/extract'\n",
        "for filename in os.listdir(folder_path):\n",
        "    if len(filename.split('_')) != 3:\n",
        "        continue\n",
        "    img = Image.open(f\"{folder_path}/{filename}\").convert('L')\n",
        "    # 获取图片的宽度和高度\n",
        "    width, height = img.size\n",
        "    cl = []\n",
        "    # 遍历每一行，如果整行像素点>=80%部分不是白色，则将该行像素点全部转换为白色\n",
        "    for y in range(height):\n",
        "        pixels = [img.getpixel((x, y)) for x in range(width)]\n",
        "        white_pixels = sum(1 for pixel in pixels if pixel == 255)\n",
        "        if white_pixels < width*0.2:\n",
        "            for x in range(width):\n",
        "                cl.append((x, y))\n",
        "    # 遍历每一列，如果整列像素点>=80%部分不是白色，则将该列像素点全部转换为白色\n",
        "    for x in range(width):\n",
        "        pixels = [img.getpixel((x, y)) for y in range(height)]\n",
        "        white_pixels = sum(1 for pixel in pixels if pixel == 255)\n",
        "        if white_pixels < height*0.2:\n",
        "            for y in range(height):\n",
        "                cl.append((x, y))\n",
        "    # 将所有的白色像素点转换为黑色\n",
        "    for x, y in cl:\n",
        "        img.putpixel((x, y), 255)\n",
        "    # 反转图片颜色\n",
        "    img = ImageOps.invert(img)\n",
        "    img.save(f\"{folder_path}/ok/ok_{filename}\")\n",
        "print(f\"Done on {timex()}\")"
      ],
      "metadata": {
        "id": "RdixvuIPMopr",
        "outputId": "92620078-f7e8-4c56-a00d-b56c047857e7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.识别数字并转化为数独\n"
      ],
      "metadata": {
        "collapsed": false,
        "id": "oqzkxEAiMopr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "Model summary: 157 layers, 7037095 parameters, 0 gradients\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0 0 3 0 0 2 0 0 6]\n",
            " [0 0 0 0 1 8 0 3 0]\n",
            " [7 1 0 0 0 0 0 0 2]\n",
            " [0 0 0 0 0 0 7 0 0]\n",
            " [3 5 0 0 6 0 0 0 0]\n",
            " [0 0 6 4 0 3 0 1 0]\n",
            " [0 0 0 0 0 0 9 4 0]\n",
            " [0 0 5 9 0 0 0 0 0]\n",
            " [9 0 2 6 0 0 0 0 0]]\n",
            "Done on 2023-04-27 03:45:20.362784\n"
          ]
        }
      ],
      "source": [
        "from torchvision.transforms import ToTensor, Resize\n",
        "from pathlib import Path\n",
        "import sys\n",
        "from models.experimental import attempt_load\n",
        "from utils.general import non_max_suppression\n",
        "from utils.torch_utils import select_device\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "global sudoku_\n",
        "\n",
        "sys.path.insert(0, str(Path('yolov5')))\n",
        "\n",
        "def load_model(model_path):\n",
        "    device = select_device()\n",
        "    model = attempt_load(model_path, device)\n",
        "    model.eval()\n",
        "    return model\n",
        "\n",
        "def predict(model, image_path):\n",
        "    device = select_device()\n",
        "    img = Image.open(image_path).convert(\"RGB\")\n",
        "    img = Resize((128, 128))(img)\n",
        "    img_tensor = ToTensor()(img).unsqueeze(0).to(device)\n",
        "    pred = model(img_tensor)[0]\n",
        "    # Apply non-max suppression\n",
        "    results = non_max_suppression(pred, conf_thres=0.25, iou_thres=0.45, classes=None, agnostic=False)\n",
        "    return results, img.size\n",
        "\n",
        "def process_images(model_path, image_folder):\n",
        "    global sudoku_\n",
        "    model = load_model(model_path)\n",
        "    sudoku = np.zeros((9, 9), dtype=np.int32)\n",
        "    for img_name in sorted(os.listdir(image_folder)):\n",
        "        if img_name.startswith(\"ok_extract_\"):\n",
        "            row = int(img_name.split(\"_\")[3].split('.')[0]) // 9\n",
        "            col = int(img_name.split(\"_\")[3].split('.')[0]) % 9\n",
        "            img_path = os.path.join(image_folder, img_name)\n",
        "            results, img_size = predict(model, img_path)\n",
        "            if len(results) > 0 and len(results[0]) > 0:\n",
        "                most_likely_class = int(results[0][0][5].item())\n",
        "                sudoku[row, col] = most_likely_class\n",
        "        else:\n",
        "            continue\n",
        "    sudoku_=sudoku\n",
        "process_images(\"detect_number.pt\", \"sudoku_pic/extract/ok\")\n",
        "print(sudoku_)\n",
        "print(f\"Done on {timex()}\")"
      ],
      "metadata": {
        "id": "YdfpptdjMopr",
        "outputId": "a8b7b9e8-cda2-4ce2-8e5f-593970ccef05",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.求解数独\n"
      ],
      "metadata": {
        "id": "pZ_JEi2-q78q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "global sudoku_2\n",
        "def solve_sudoku_from_np_array(input_array):\n",
        "    global sudoku_2\n",
        "    input_array = input_array.copy() \n",
        "    def dfs(x, y):\n",
        "        if x == 9:\n",
        "            return True\n",
        "        if y == 9:\n",
        "            return dfs(x + 1, 0)\n",
        "        if input_array[x][y]:\n",
        "            return dfs(x, y + 1)\n",
        "        \n",
        "        id = xy_id[x][y]\n",
        "        for k in range(1, 10):\n",
        "            if hang[x][k] or lie[y][k] or kuai[id][k]:\n",
        "                continue\n",
        "            input_array[x][y] = k\n",
        "            hang[x][k] = 1\n",
        "            lie[y][k] = 1\n",
        "            kuai[id][k] = 1\n",
        "            \n",
        "            if dfs(x, y + 1):\n",
        "                return True\n",
        "            \n",
        "            input_array[x][y] = 0\n",
        "            hang[x][k] = 0\n",
        "            lie[y][k] = 0\n",
        "            kuai[id][k] = 0\n",
        "        \n",
        "        return False\n",
        "\n",
        "    hang = np.zeros((9, 10), dtype=int)\n",
        "    lie = np.zeros((9, 10), dtype=int)\n",
        "    kuai = np.zeros((9, 10), dtype=int)\n",
        "\n",
        "    xy_id = np.array([\n",
        "        [0, 0, 0, 1, 1, 1, 2, 2, 2],\n",
        "        [0, 0, 0, 1, 1, 1, 2, 2, 2],\n",
        "        [0, 0, 0, 1, 1, 1, 2, 2, 2],\n",
        "        [3, 3, 3, 4, 4, 4, 5, 5, 5],\n",
        "        [3, 3, 3, 4, 4, 4, 5, 5, 5],\n",
        "        [3, 3, 3, 4, 4, 4, 5, 5, 5],\n",
        "        [6, 6, 6, 7, 7, 7, 8, 8, 8],\n",
        "        [6, 6, 6, 7, 7, 7, 8, 8, 8],\n",
        "        [6, 6, 6, 7, 7, 7, 8, 8, 8]\n",
        "    ])\n",
        "\n",
        "    for i in range(9):\n",
        "        for j in range(9):\n",
        "            if input_array[i][j] != 0:\n",
        "                num = input_array[i][j]\n",
        "                hang[i][num] = 1\n",
        "                lie[j][num] = 1\n",
        "                id = xy_id[i][j]\n",
        "                kuai[id][num] = 1\n",
        "\n",
        "    dfs(0, 0)\n",
        "\n",
        "    sudoku_2=input_array\n",
        "print(sudoku_)\n",
        "solve_sudoku_from_np_array(sudoku_)\n",
        "print(sudoku_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jM07K3oJq-I8",
        "outputId": "ffdd438e-c141-4fdb-bf00-c1c0238b705c"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0 0 3 0 0 2 0 0 6]\n",
            " [0 0 0 0 1 8 0 3 0]\n",
            " [7 1 0 0 0 0 0 0 2]\n",
            " [0 0 0 0 0 0 7 0 0]\n",
            " [3 5 0 0 6 0 0 0 0]\n",
            " [0 0 6 4 0 3 0 1 0]\n",
            " [0 0 0 0 0 0 9 4 0]\n",
            " [0 0 5 9 0 0 0 0 0]\n",
            " [9 0 2 6 0 0 0 0 0]]\n",
            "[[5 8 3 7 4 2 1 9 6]\n",
            " [2 6 9 5 1 8 4 3 7]\n",
            " [7 1 4 3 9 6 8 5 2]\n",
            " [4 9 1 8 2 5 7 6 3]\n",
            " [3 5 7 1 6 9 2 8 4]\n",
            " [8 2 6 4 7 3 5 1 9]\n",
            " [6 3 8 2 5 7 9 4 1]\n",
            " [1 7 5 9 3 4 6 2 8]\n",
            " [9 4 2 6 8 1 3 7 5]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6.填回原图"
      ],
      "metadata": {
        "id": "fuH1RSUVxm28"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def fill_sudoku_numbers(original_image_path, old_array, new_array):\n",
        "    old_array = np.array(old_array)\n",
        "    new_array = np.array(new_array)\n",
        "    print(old_array)\n",
        "    print(new_array)\n",
        "    # 加载原始图像\n",
        "    original_image = cv2.imread(original_image_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "    # 计算每个单元格的大小\n",
        "    cell_width = original_image.shape[1] // 9\n",
        "    cell_height = original_image.shape[0] // 9\n",
        "\n",
        "    # 设置字体\n",
        "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "    font_scale = (cell_width + cell_height) / 100\n",
        "    font_thickness = int((cell_width + cell_height) / 25)\n",
        "\n",
        "    for i in range(9):\n",
        "        for j in range(9):\n",
        "            if old_array[i][j] == 0 and new_array[i][j] != 0:\n",
        "                # 计算数字在图像中的坐标\n",
        "                x = cell_width * j + cell_width // 2\n",
        "                y = cell_height * i + cell_height // 2\n",
        "                print(x,y)\n",
        "                # 在原始图像上填充数字\n",
        "                cv2.putText(original_image, str(new_array[i][j]), (x, y), font, font_scale, (0, 0, 255), font_thickness, cv2.LINE_AA)\n",
        "\n",
        "    # 保存填充后的图像\n",
        "    filled_image_path = \"/content/sudoku_pic/extract/filled_extract_1.png\"\n",
        "    cv2.imwrite(filled_image_path, original_image)\n",
        "\n",
        "    return filled_image_path\n",
        "\n",
        "original_image_path = \"/content/sudoku_pic/extract/extract_1.png\"\n",
        "fill_sudoku_numbers(original_image_path,sudoku_,sudoku_2)\n"
      ],
      "metadata": {
        "id": "XoK-Daiaxqwc",
        "outputId": "dc136dfa-f0c2-4b34-b239-7dd7a6e3396d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0 0 3 0 0 2 0 0 6]\n",
            " [0 0 0 0 1 8 0 3 0]\n",
            " [7 1 0 0 0 0 0 0 2]\n",
            " [0 0 0 0 0 0 7 0 0]\n",
            " [3 5 0 0 6 0 0 0 0]\n",
            " [0 0 6 4 0 3 0 1 0]\n",
            " [0 0 0 0 0 0 9 4 0]\n",
            " [0 0 5 9 0 0 0 0 0]\n",
            " [9 0 2 6 0 0 0 0 0]]\n",
            "[[5 8 3 7 4 2 1 9 6]\n",
            " [2 6 9 5 1 8 4 3 7]\n",
            " [7 1 4 3 9 6 8 5 2]\n",
            " [4 9 1 8 2 5 7 6 3]\n",
            " [3 5 7 1 6 9 2 8 4]\n",
            " [8 2 6 4 7 3 5 1 9]\n",
            " [6 3 8 2 5 7 9 4 1]\n",
            " [1 7 5 9 3 4 6 2 8]\n",
            " [9 4 2 6 8 1 3 7 5]]\n",
            "45 45\n",
            "135 45\n",
            "315 45\n",
            "405 45\n",
            "585 45\n",
            "675 45\n",
            "45 136\n",
            "135 136\n",
            "225 136\n",
            "315 136\n",
            "585 136\n",
            "765 136\n",
            "225 227\n",
            "315 227\n",
            "405 227\n",
            "495 227\n",
            "585 227\n",
            "675 227\n",
            "45 318\n",
            "135 318\n",
            "225 318\n",
            "315 318\n",
            "405 318\n",
            "495 318\n",
            "675 318\n",
            "765 318\n",
            "225 409\n",
            "315 409\n",
            "495 409\n",
            "585 409\n",
            "675 409\n",
            "765 409\n",
            "45 500\n",
            "135 500\n",
            "405 500\n",
            "585 500\n",
            "765 500\n",
            "45 591\n",
            "135 591\n",
            "225 591\n",
            "315 591\n",
            "405 591\n",
            "495 591\n",
            "765 591\n",
            "45 682\n",
            "135 682\n",
            "405 682\n",
            "495 682\n",
            "585 682\n",
            "675 682\n",
            "765 682\n",
            "135 773\n",
            "405 773\n",
            "495 773\n",
            "585 773\n",
            "675 773\n",
            "765 773\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/sudoku_pic/extract/filled_extract_1.png'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}