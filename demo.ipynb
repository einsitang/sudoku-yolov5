{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## 基于yolov5的数独检测\n",
        "### 0.环境安装"
      ],
      "metadata": {
        "collapsed": false,
        "id": "rSiWMcPFMopn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'sudoku' already exists and is not an empty directory.\n",
            "mv: cannot stat 'sudoku/*': No such file or directory\n",
            "fatal: destination path 'yolov5' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/pk5ls20/sudoku.git\n",
        "!mv sudoku/* .\n",
        "%pip install -qr requirements.txt\n",
        "!git clone https://github.com/ultralytics/yolov5.git"
      ],
      "metadata": {
        "id": "YVSI364EMopp",
        "outputId": "5dc929d2-5e6e-4afb-ca63-17797a5cf9c6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.提取数独"
      ],
      "metadata": {
        "collapsed": false,
        "id": "6hb90fvEMopq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torch/hub.py:286: UserWarning: You are about to download and run code from an untrusted repository. In a future release, this won't be allowed. To add the repository to your trusted list, change the command to {calling_fn}(..., trust_repo=False) and a command prompt will appear asking for an explicit confirmation of trust, or load(..., trust_repo=True), which will assume that the prompt is to be answered with 'yes'. You can also use load(..., trust_repo='check') which will only prompt for confirmation if the repo is not already trusted. This will eventually be the default behaviour\n",
            "  warnings.warn(\n",
            "Downloading: \"https://github.com/ultralytics/yolov5/zipball/master\" to /root/.cache/torch/hub/master.zip\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31m\u001b[1mrequirements:\u001b[0m /root/.cache/torch/hub/requirements.txt not found, check failed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fusing layers... \n",
            "Model summary: 157 layers, 7012822 parameters, 0 gradients, 15.8 GFLOPs\n",
            "Adding AutoShape... \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "正在处理1.png...提取成功！\n",
            "Done on 2023-04-27 00:59:16.548206\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import datetime\n",
        "import cv2\n",
        "model = torch.hub.load('ultralytics/yolov5', 'custom', path='detect_sudoku.pt')\n",
        "input_path = 'sudoku_pic'\n",
        "output_path = 'sudoku_pic/extract'\n",
        "timex = lambda :datetime.datetime.now()\n",
        "for file_name in os.listdir(input_path):\n",
        "    if file_name.endswith('.jpg') or file_name.endswith('.png'):\n",
        "        print(f\"正在处理{file_name}\", end='')\n",
        "        img = cv2.imread(os.path.join(input_path, file_name))\n",
        "        # 使用YOLOv5检测\n",
        "        results = model(img)\n",
        "        # 得到置信度最高的数独检测结果\n",
        "        sudoku_detection = None\n",
        "        for result in results.pred[0]:\n",
        "            if result[-1] == 0 and result[-2] > 0.8:\n",
        "                sudoku_detection = result\n",
        "                break\n",
        "        # 提取数独\n",
        "        if sudoku_detection is not None:\n",
        "            xmin, ymin, xmax, ymax, confidence = sudoku_detection[:5]\n",
        "            sudoku = img[int(ymin):int(ymax), int(xmin):int(xmax)]\n",
        "            cv2.imwrite(os.path.join(output_path, f\"extract_{file_name}\"), sudoku)\n",
        "            print(f\"...提取成功！\")\n",
        "        else:\n",
        "            print(f\"...{file_name}未检测到数独！\")\n",
        "print(f\"Done on {timex()}\")"
      ],
      "metadata": {
        "id": "LKDd4Zs0Mopq",
        "outputId": "fadebb46-1a80-4531-82ff-5c3d83c53cb5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.提取数独中的数字"
      ],
      "metadata": {
        "collapsed": false,
        "id": "FYMmP4XDMopq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done on 2023-04-27 00:59:23.746297\n"
          ]
        }
      ],
      "source": [
        "# Iterate over images in input folder\n",
        "fp = list(os.listdir(output_path))\n",
        "for file_name in fp:\n",
        "    if file_name.split('_')[0] != 'extract':\n",
        "        continue\n",
        "    # Load image\n",
        "    img = cv2.imread(os.path.join(output_path, file_name))\n",
        "    # Get dimensions of image\n",
        "    height, width, _ = img.shape\n",
        "    # Calculate size of each small image\n",
        "    size = int(height / 9)\n",
        "    # Iterate over rows and columns of small images\n",
        "    for row in range(9):\n",
        "        for col in range(9):\n",
        "            # Calculate coordinates of small image\n",
        "            x1 = col * size\n",
        "            y1 = row * size\n",
        "            x2 = x1 + size\n",
        "            y2 = y1 + size\n",
        "            # Crop small image from main image\n",
        "            small_img = img[y1:y2, x1:x2]\n",
        "            # Save small image to output folder\n",
        "            small_img_file_name = '{}_{}.png'.format(os.path.splitext(file_name)[0], row * 9 + col)\n",
        "            cv2.imwrite(os.path.join(output_path, small_img_file_name), small_img)\n",
        "print(f\"Done on {timex()}\")"
      ],
      "metadata": {
        "id": "lcwxRyO3Mopr",
        "outputId": "cb6bde2b-00fd-4bdb-c8bd-fe8a3fee0077",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.单个数字图片预处理\n",
        "在识别单个数字之前，需要对图片进行预处理。\n",
        "受限于训练模型，进行二值化+去黑线的预处理可以大幅度提高识别准确率"
      ],
      "metadata": {
        "collapsed": false,
        "id": "FWCQKS4iMopr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done on 2023-04-27 00:59:27.328855\n"
          ]
        }
      ],
      "source": [
        "from PIL import Image, ImageOps\n",
        "import os\n",
        "\n",
        "# 读取图片并转换为黑白图\n",
        "folder_path = 'sudoku_pic/extract'\n",
        "for filename in os.listdir(folder_path):\n",
        "    if len(filename.split('_')) != 3:\n",
        "        continue\n",
        "    img = Image.open(f\"{folder_path}/{filename}\").convert('L')\n",
        "    # 获取图片的宽度和高度\n",
        "    width, height = img.size\n",
        "    cl = []\n",
        "    # 遍历每一行，如果整行像素点>=80%部分不是白色，则将该行像素点全部转换为白色\n",
        "    for y in range(height):\n",
        "        pixels = [img.getpixel((x, y)) for x in range(width)]\n",
        "        white_pixels = sum(1 for pixel in pixels if pixel == 255)\n",
        "        if white_pixels < width*0.2:\n",
        "            for x in range(width):\n",
        "                cl.append((x, y))\n",
        "    # 遍历每一列，如果整列像素点>=80%部分不是白色，则将该列像素点全部转换为白色\n",
        "    for x in range(width):\n",
        "        pixels = [img.getpixel((x, y)) for y in range(height)]\n",
        "        white_pixels = sum(1 for pixel in pixels if pixel == 255)\n",
        "        if white_pixels < height*0.2:\n",
        "            for y in range(height):\n",
        "                cl.append((x, y))\n",
        "    # 将所有的白色像素点转换为黑色\n",
        "    for x, y in cl:\n",
        "        img.putpixel((x, y), 255)\n",
        "    # 反转图片颜色\n",
        "    img = ImageOps.invert(img)\n",
        "    img.save(f\"{folder_path}/ok/ok_{filename}\")\n",
        "print(f\"Done on {timex()}\")"
      ],
      "metadata": {
        "id": "RdixvuIPMopr",
        "outputId": "1d456251-68f5-40a5-f7dd-3d974fcdf0ce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.识别数字并转化为数独\n"
      ],
      "metadata": {
        "collapsed": false,
        "id": "oqzkxEAiMopr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "Model summary: 157 layers, 7037095 parameters, 0 gradients\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "YOLOv5 🚀 2023-4-27 Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0 4 1 0 0 0 3 8 0]\n",
            " [5 0 0 0 4 0 0 0 7]\n",
            " [8 0 0 7 0 3 0 0 4]\n",
            " [0 0 7 0 2 0 8 0 0]\n",
            " [0 6 0 3 0 8 0 9 0]\n",
            " [0 0 3 0 9 0 6 0 0]\n",
            " [3 0 0 2 0 1 0 0 6]\n",
            " [6 0 0 0 3 0 0 0 8]\n",
            " [0 7 4 0 0 0 2 3 0]]\n",
            "Done on 2023-04-27 00:59:30.622733\n"
          ]
        }
      ],
      "source": [
        "from torchvision.transforms import ToTensor, Resize\n",
        "from pathlib import Path\n",
        "import sys\n",
        "from models.experimental import attempt_load\n",
        "from utils.general import non_max_suppression\n",
        "from utils.torch_utils import select_device\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "sys.path.insert(0, str(Path('yolov5')))\n",
        "\n",
        "def load_model(model_path):\n",
        "    device = select_device()\n",
        "    model = attempt_load(model_path, device)\n",
        "    model.eval()\n",
        "    return model\n",
        "\n",
        "def predict(model, image_path):\n",
        "    device = select_device()\n",
        "    img = Image.open(image_path).convert(\"RGB\")\n",
        "    img = Resize((128, 128))(img)\n",
        "    img_tensor = ToTensor()(img).unsqueeze(0).to(device)\n",
        "    pred = model(img_tensor)[0]\n",
        "    # Apply non-max suppression\n",
        "    results = non_max_suppression(pred, conf_thres=0.25, iou_thres=0.45, classes=None, agnostic=False)\n",
        "    return results, img.size\n",
        "\n",
        "def process_images(model_path, image_folder):\n",
        "    model = load_model(model_path)\n",
        "    sudoku = np.zeros((9, 9), dtype=np.int32)\n",
        "    for img_name in sorted(os.listdir(image_folder)):\n",
        "        if img_name.startswith(\"ok_extract_\"):\n",
        "            row = int(img_name.split(\"_\")[3].split('.')[0]) // 9\n",
        "            col = int(img_name.split(\"_\")[3].split('.')[0]) % 9\n",
        "            img_path = os.path.join(image_folder, img_name)\n",
        "            results, img_size = predict(model, img_path)\n",
        "            if len(results) > 0 and len(results[0]) > 0:\n",
        "                most_likely_class = int(results[0][0][5].item())\n",
        "                sudoku[row, col] = most_likely_class\n",
        "        else:\n",
        "            continue\n",
        "    print(sudoku)\n",
        "process_images(\"detect_number.pt\", \"sudoku_pic/extract/ok\")\n",
        "print(f\"Done on {timex()}\")"
      ],
      "metadata": {
        "id": "YdfpptdjMopr",
        "outputId": "e1e5b3c7-8787-4ba3-f771-fd5adc173a82",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}